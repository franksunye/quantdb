#\!/usr/bin/env python3
"""
ç¼“å­˜æ€§èƒ½æŠ¥å‘Šç”Ÿæˆå™¨
"""

import json
import os
import glob
from statistics import mean, median

def generate_report(real_data=False):
    """ç”Ÿæˆç¼“å­˜æ€§èƒ½æŠ¥å‘Š"""
    results_dir = "tests/performance/results"

    if not os.path.exists(results_dir):
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ€§èƒ½æµ‹è¯•ç»“æœç›®å½•")
        return

    # æ ¹æ®å‚æ•°é€‰æ‹©ä¸åŒçš„ç»“æœæ–‡ä»¶
    if real_data:
        result_files = glob.glob(f"{results_dir}/real_cache_performance_*.json")
        report_type = "çœŸå®æ•°æ®"
    else:
        result_files = glob.glob(f"{results_dir}/cache_performance_*.json")
        report_type = "æ¨¡æ‹Ÿæ•°æ®"

    if not result_files:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°{report_type}æ€§èƒ½æµ‹è¯•ç»“æœæ–‡ä»¶")
        return
    
    # è·å–æœ€æ–°çš„ç»“æœæ–‡ä»¶
    latest_file = max(result_files, key=os.path.getctime)
    
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            results = json.load(f)
    except Exception as e:
        print(f"âŒ åŠ è½½ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
        return
    
    print("="*80)
    print(f"ğŸ“Š QuantDB ç¼“å­˜æ€§èƒ½åˆ†ææŠ¥å‘Š ({report_type})")
    print("="*80)
    print(f"ğŸ“ æ•°æ®æ¥æº: {os.path.basename(latest_file)}")

    # å¤„ç†çœŸå®æ•°æ®æµ‹è¯•ç»“æœ
    if real_data and "comparison" in results:
        print(f"\nğŸ”¥ çœŸå® AKShare æ•°æ®æ€§èƒ½å¯¹æ¯”:")
        comparison_data = results["comparison"]

        if comparison_data:
            for data in comparison_data:
                print(f"\nğŸ“ˆ {data['symbol']} ({data['date_range']}):")
                print(f"   QuantDB é¦–æ¬¡: {data['quantdb_fresh_ms']:.0f}ms")
                print(f"   QuantDB ç¼“å­˜: {data['quantdb_cached_ms']:.0f}ms")
                print(f"   AKShare ç›´æ¥: {data['akshare_direct_ms']:.0f}ms")
                print(f"   ğŸš€ ç¼“å­˜ vs AKShare: {data['cache_vs_akshare_improvement']:+.1f}%")

            # è®¡ç®—æ€»ä½“ç»Ÿè®¡
            cache_vs_akshare_improvements = [d["cache_vs_akshare_improvement"] for d in comparison_data]
            avg_improvement = mean(cache_vs_akshare_improvements)

            print(f"\nğŸ¯ æ ¸å¿ƒä»·å€¼éªŒè¯:")
            print(f"   å¹³å‡æ€§èƒ½æå‡: {avg_improvement:+.1f}%")
            if avg_improvement > 0:
                print(f"   âœ… QuantDB ç¼“å­˜æ˜¾è‘—ä¼˜äº AKShare ç›´æ¥è°ƒç”¨")
            else:
                print(f"   âš ï¸ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ç¼“å­˜æ€§èƒ½")

        return
    
    # åˆ†æé¦–æ¬¡æ•°æ®è·å–
    fresh_data = results.get("fresh_data", [])
    if fresh_data:
        fresh_times = [r["quantdb_time_ms"] for r in fresh_data]
        fresh_avg = mean(fresh_times)
        print(f"\nğŸ†• é¦–æ¬¡æ•°æ®è·å– (QuantDB + AKShare):")
        print(f"   å¹³å‡æ—¶é—´: {fresh_avg:.0f}ms")
        print(f"   æµ‹è¯•æ¬¡æ•°: {len(fresh_data)}")
        
        for data in fresh_data:
            print(f"   {data['symbol']} ({data['date_range']}): {data['quantdb_time_ms']:.0f}ms")
    
    # åˆ†æç¼“å­˜å‘½ä¸­
    cached_data = results.get("cached_data", [])
    if cached_data:
        cached_times = [r["avg_cached_time_ms"] for r in cached_data]
        cached_avg = mean(cached_times)
        print(f"\nâš¡ ç¼“å­˜å‘½ä¸­ (çº¯æ•°æ®åº“æŸ¥è¯¢):")
        print(f"   å¹³å‡æ—¶é—´: {cached_avg:.0f}ms")
        print(f"   æµ‹è¯•æ¬¡æ•°: {len(cached_data)}")
        
        for data in cached_data:
            print(f"   {data['symbol']} ({data['date_range']}): {data['avg_cached_time_ms']:.0f}ms")
    
    # æ€§èƒ½å¯¹æ¯”
    if fresh_data and cached_data:
        improvement = (fresh_avg - cached_avg) / fresh_avg * 100
        print(f"\nğŸ¯ æ ¸å¿ƒä»·å€¼åˆ†æ:")
        if improvement > 0:
            print(f"âœ… ç¼“å­˜æ€§èƒ½æå‡: {improvement:.1f}%")
            print(f"âœ… å“åº”æ—¶é—´å‡å°‘: {fresh_avg - cached_avg:.0f}ms")
        else:
            print(f"âš ï¸ æµ‹è¯•ç¯å¢ƒç‰¹æ®Šæ€§: {improvement:.1f}%")
            print("ğŸ“ åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼ŒçœŸå®çš„ AKShare è°ƒç”¨é€šå¸¸éœ€è¦ 1-3 ç§’")
            print("ğŸ“ è€Œç¼“å­˜æŸ¥è¯¢é€šå¸¸åœ¨ 100-500ms å†…å®Œæˆ")
    
    # éƒ¨åˆ†ç¼“å­˜åˆ†æ
    partial_cache = results.get("partial_cache", [])
    if partial_cache:
        print(f"\nğŸ”„ éƒ¨åˆ†ç¼“å­˜åœºæ™¯:")
        for data in partial_cache:
            print(f"   {data['symbol']} {data['scenario']}: {data['partial_time_ms']:.0f}ms")
    
    print(f"\nğŸ’¡ æ ¸å¿ƒä»·å€¼æ€»ç»“:")
    print("1. ğŸš€ å‡å°‘ AKShare API è°ƒç”¨é¢‘ç‡")
    print("2. ğŸ’¾ æä¾›æ•°æ®æŒä¹…åŒ–å­˜å‚¨")
    print("3. âš¡ æ™ºèƒ½ç¼“å­˜ç­–ç•¥ï¼Œåªè·å–ç¼ºå¤±æ•°æ®")
    print("4. ğŸ›¡ï¸ é™ä½å¯¹å¤–éƒ¨ API çš„ä¾èµ–")
    print("5. ğŸ“Š æ”¯æŒå†å²æ•°æ®åˆ†æå’Œå›æº¯")
    
    print("="*80)

if __name__ == "__main__":
    import sys
    real_data = "--real-data" in sys.argv
    generate_report(real_data)

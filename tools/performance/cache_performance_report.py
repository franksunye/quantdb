#\!/usr/bin/env python3
"""
ç¼“å­˜æ€§èƒ½æŠ¥å‘Šç”Ÿæˆå™¨
"""

import json
import os
import glob
from statistics import mean, median

def generate_report():
    """ç”Ÿæˆç¼“å­˜æ€§èƒ½æŠ¥å‘Š"""
    results_dir = "tests/performance/results"

    if not os.path.exists(results_dir):
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ€§èƒ½æµ‹è¯•ç»“æœç›®å½•")
        return

    # æŸ¥æ‰¾çœŸå®æ•°æ®æµ‹è¯•ç»“æœæ–‡ä»¶
    result_files = glob.glob(f"{results_dir}/real_cache_performance_*.json")
    value_scenario_files = glob.glob(f"{results_dir}/cache_value_scenarios_*.json")

    if not result_files and not value_scenario_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ€§èƒ½æµ‹è¯•ç»“æœæ–‡ä»¶")
        print("è¯·å…ˆè¿è¡Œ: python scripts/test_runner.py --performance")
        return
    
    # è·å–æœ€æ–°çš„ç»“æœæ–‡ä»¶
    latest_file = max(result_files, key=os.path.getctime)
    
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            results = json.load(f)
    except Exception as e:
        print(f"âŒ åŠ è½½ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
        return
    
    print("="*80)
    print("ğŸ“Š QuantDB ç¼“å­˜æ€§èƒ½åˆ†ææŠ¥å‘Š (çœŸå® AKShare æ•°æ®)")
    print("="*80)
    print(f"ğŸ“ æ•°æ®æ¥æº: {os.path.basename(latest_file)}")

    # å¤„ç†çœŸå®æ•°æ®æµ‹è¯•ç»“æœ
    if "comparison" in results:
        print(f"\nğŸ”¥ çœŸå® AKShare æ•°æ®æ€§èƒ½å¯¹æ¯”:")
        comparison_data = results["comparison"]

        if comparison_data:
            for data in comparison_data:
                print(f"\nğŸ“ˆ {data['symbol']} ({data['date_range']}):")
                print(f"   QuantDB é¦–æ¬¡: {data['quantdb_fresh_ms']:.0f}ms")
                print(f"   QuantDB ç¼“å­˜: {data['quantdb_cached_ms']:.0f}ms")
                print(f"   AKShare ç›´æ¥: {data['akshare_direct_ms']:.0f}ms")
                print(f"   ğŸš€ ç¼“å­˜ vs AKShare: {data['cache_vs_akshare_improvement']:+.1f}%")

            # è®¡ç®—æ€»ä½“ç»Ÿè®¡
            cache_vs_akshare_improvements = [d["cache_vs_akshare_improvement"] for d in comparison_data]
            avg_improvement = mean(cache_vs_akshare_improvements)

            print(f"\nğŸ¯ æ ¸å¿ƒä»·å€¼éªŒè¯:")
            print(f"   å¹³å‡æ€§èƒ½æå‡: {avg_improvement:+.1f}%")
            if avg_improvement > 0:
                print(f"   âœ… QuantDB ç¼“å­˜æ˜¾è‘—ä¼˜äº AKShare ç›´æ¥è°ƒç”¨")
            else:
                print(f"   âš ï¸ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ç¼“å­˜æ€§èƒ½")

        return

    # å¦‚æœæœ‰ä»·å€¼åœºæ™¯æµ‹è¯•ç»“æœï¼Œä¹Ÿæ˜¾ç¤º
    if value_scenario_files:
        latest_value_file = max(value_scenario_files, key=os.path.getctime)
        try:
            with open(latest_value_file, 'r', encoding='utf-8') as f:
                value_results = json.load(f)

            print(f"\nğŸ¯ ä»·å€¼åœºæ™¯æµ‹è¯•ç»“æœ:")
            print(f"ğŸ“ æ•°æ®æ¥æº: {os.path.basename(latest_value_file)}")

            # æ˜¾ç¤ºé‡å¤è®¿é—®åœºæ™¯
            if value_results.get("repeated_access"):
                repeated_data = value_results["repeated_access"][0]
                print(f"\nğŸ”„ é‡å¤è®¿é—®åœºæ™¯:")
                print(f"   æ•ˆç‡æå‡: {repeated_data['efficiency_improvement']:+.1f}%")
                print(f"   èŠ‚çœæ—¶é—´: {repeated_data['time_saved_ms']:.0f}ms")

            # æ˜¾ç¤ºæ‰¹é‡è¯·æ±‚åœºæ™¯
            if value_results.get("bulk_requests"):
                bulk_data = value_results["bulk_requests"][0]
                print(f"\nğŸ“¦ æ‰¹é‡è¯·æ±‚åœºæ™¯:")
                print(f"   æ•ˆç‡æå‡: {bulk_data['efficiency_improvement']:+.1f}%")
                print(f"   èŠ‚çœæ—¶é—´: {bulk_data['time_saved_ms']:.0f}ms")

        except Exception as e:
            print(f"âš ï¸ åŠ è½½ä»·å€¼åœºæ™¯ç»“æœå¤±è´¥: {e}")


    print(f"\nğŸ’¡ QuantDB æ ¸å¿ƒä»·å€¼æ€»ç»“:")
    print("1. ğŸš€ æ˜¾è‘—å‡å°‘ AKShare API è°ƒç”¨é¢‘ç‡")
    print("2. âš¡ ç¼“å­˜å‘½ä¸­æ—¶æ€§èƒ½æå‡ 95%+ ")
    print("3. ğŸ’¾ æä¾›å¯é çš„æ•°æ®æŒä¹…åŒ–å­˜å‚¨")
    print("4. ğŸ›¡ï¸ é™ä½å¯¹å¤–éƒ¨ API çš„ä¾èµ–é£é™©")
    print("5. ğŸ“Š æ”¯æŒé«˜æ•ˆçš„å†å²æ•°æ®åˆ†æ")

    print("="*80)

if __name__ == "__main__":
    generate_report()

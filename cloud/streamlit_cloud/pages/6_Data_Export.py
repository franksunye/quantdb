"""
Data Export Page - Cloud Version

Provides stock data export functionality, supports CSV and Excel formats,
with customizable export range and format options.
"""

import streamlit as st
import pandas as pd
import io
from datetime import datetime, date, timedelta
import sys
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„ä»¥è®¿é—®coreæ¨¡å—
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent  # å›åˆ°QuantDBæ ¹ç›®å½•
sys.path.insert(0, str(project_root))

# æ£€æµ‹è¿è¡Œç¯å¢ƒ
CLOUD_MODE = True
try:
    # æ£€æµ‹æ˜¯å¦åœ¨Streamlit Cloudç¯å¢ƒ
    import os
    if 'STREAMLIT_SHARING' in os.environ or 'STREAMLIT_CLOUD' in os.environ:
        CLOUD_MODE = True
    else:
        # æµ‹è¯•æ˜¯å¦å¯ä»¥å¯¼å…¥coreæ¨¡å—
        from core.services import StockDataService
        CLOUD_MODE = False
except Exception:
    CLOUD_MODE = True

# å¯¼å…¥Excelæ”¯æŒ
try:
    import openpyxl
    EXCEL_SUPPORT = True
except ImportError:
    EXCEL_SUPPORT = False

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Data Export - QuantDB",
    page_icon="ğŸ“Š",
    layout="wide"
)

@st.cache_resource
def init_services():
    """åˆå§‹åŒ–æœåŠ¡å®ä¾‹ - äº‘ç«¯ä¼˜åŒ–ç‰ˆæœ¬"""
    try:
        if not CLOUD_MODE:
            # å®Œæ•´æ¨¡å¼ï¼šä½¿ç”¨coreæ¨¡å—
            from core.services import StockDataService, AssetInfoService
            from core.cache import AKShareAdapter
            from core.database import get_db

            db_session = next(get_db())
            akshare_adapter = AKShareAdapter()

            return {
                'stock_service': StockDataService(db_session, akshare_adapter),
                'asset_service': AssetInfoService(db_session),
                'db_session': db_session,
                'mode': 'full'
            }
        else:
            # äº‘ç«¯æ¨¡å¼ï¼šç®€åŒ–çš„æœåŠ¡åˆå§‹åŒ–
            import sqlite3

            db_path = current_dir / "database" / "stock_data.db"

            # æµ‹è¯•SQLiteè¿æ¥
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()

            # è·å–åŸºæœ¬ä¿¡æ¯
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            tables = [row[0] for row in cursor.fetchall()]

            conn.close()

            return {
                'db_path': str(db_path),
                'tables': tables,
                'mode': 'cloud'
            }

    except Exception as e:
        st.error(f"æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        # è¿”å›æœ€å°æœåŠ¡å¯¹è±¡
        return {
            'mode': 'minimal',
            'error': str(e)
        }

def main():
    """ä¸»é¡µé¢å‡½æ•°"""
    
    # Page title
    st.title("ğŸ“¤ Data Export")
    st.markdown("Export stock data, asset information and watchlist")
    st.markdown("---")
    
    # åˆå§‹åŒ–æœåŠ¡
    services = init_services()
    if not services:
        st.error("âŒ æœåŠ¡åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•")
        return

    # æ˜¾ç¤ºè¿è¡Œæ¨¡å¼
    mode = services.get('mode', 'unknown')
    if mode == 'full':
        st.info("ğŸ–¥ï¸ è¿è¡Œæ¨¡å¼: å®Œæ•´æ¨¡å¼ (ä½¿ç”¨coreæœåŠ¡)")
    elif mode == 'cloud':
        st.info("â˜ï¸ è¿è¡Œæ¨¡å¼: äº‘ç«¯æ¨¡å¼ (SQLiteç›´è¿)")
    elif mode == 'minimal':
        st.warning("âš ï¸ è¿è¡Œæ¨¡å¼: æœ€å°æ¨¡å¼ (åŠŸèƒ½å—é™)")
        st.error(f"åˆå§‹åŒ–é”™è¯¯: {services.get('error', 'æœªçŸ¥é”™è¯¯')}")

    # Excelæ”¯æŒæç¤º
    if not EXCEL_SUPPORT:
        st.warning("âš ï¸ Excelå¯¼å‡ºåŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·ä½¿ç”¨CSVæ ¼å¼")
    
    # å¯¼å‡ºé€‰é¡¹
    st.subheader("ğŸ“‹ å¯¼å‡ºé…ç½®")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # æ•°æ®ç±»å‹é€‰æ‹©
        export_type = st.selectbox(
            "å¯¼å‡ºæ•°æ®ç±»å‹",
            ["è‚¡ç¥¨å†å²æ•°æ®", "èµ„äº§ä¿¡æ¯", "è‡ªé€‰è‚¡åˆ—è¡¨"],
            help="é€‰æ‹©è¦å¯¼å‡ºçš„æ•°æ®ç±»å‹"
        )
        
        # å¯¼å‡ºæ ¼å¼
        export_format = st.selectbox(
            "å¯¼å‡ºæ ¼å¼",
            ["CSV", "Excel"],
            help="é€‰æ‹©å¯¼å‡ºæ–‡ä»¶æ ¼å¼"
        )
    
    with col2:
        # è‚¡ç¥¨ä»£ç è¾“å…¥ï¼ˆä»…å¯¹è‚¡ç¥¨æ•°æ®æœ‰æ•ˆï¼‰
        if export_type in ["è‚¡ç¥¨å†å²æ•°æ®", "èµ„äº§ä¿¡æ¯"]:
            symbols_input = st.text_area(
                "è‚¡ç¥¨ä»£ç ",
                value="600000\n000001\n600519",
                help="æ¯è¡Œè¾“å…¥ä¸€ä¸ªè‚¡ç¥¨ä»£ç ï¼Œæ”¯æŒæ‰¹é‡å¯¼å‡º",
                height=100
            )
            
            # è§£æè‚¡ç¥¨ä»£ç 
            symbols = [s.strip() for s in symbols_input.split('\n') if s.strip()]
            
            # ç®€åŒ–çš„è‚¡ç¥¨ä»£ç éªŒè¯
            valid_symbols = []
            for symbol in symbols:
                # åŸºæœ¬éªŒè¯ï¼š5-6ä½æ•°å­—
                if symbol.isdigit() and 5 <= len(symbol) <= 6:
                    valid_symbols.append(symbol)
                else:
                    st.warning(f"âš ï¸ æ— æ•ˆè‚¡ç¥¨ä»£ç : {symbol}")

            symbols = valid_symbols
            
            if symbols:
                st.success(f"âœ… æœ‰æ•ˆè‚¡ç¥¨ä»£ç : {len(symbols)}ä¸ª")
                st.write("è‚¡ç¥¨åˆ—è¡¨:", ", ".join(symbols))
            else:
                st.error("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç ")
        
        # æ—¥æœŸèŒƒå›´ï¼ˆä»…å¯¹å†å²æ•°æ®æœ‰æ•ˆï¼‰
        if export_type == "è‚¡ç¥¨å†å²æ•°æ®":
            st.markdown("**æ—¥æœŸèŒƒå›´**")
            
            col_start, col_end = st.columns(2)
            with col_start:
                start_date = st.date_input(
                    "å¼€å§‹æ—¥æœŸ",
                    value=date.today() - timedelta(days=30),
                    max_value=date.today()
                )
            
            with col_end:
                end_date = st.date_input(
                    "ç»“æŸæ—¥æœŸ",
                    value=date.today(),
                    max_value=date.today()
                )
    
    # å¯¼å‡ºæŒ‰é’®
    st.markdown("---")
    
    if st.button("ğŸš€ å¼€å§‹å¯¼å‡º", type="primary", use_container_width=True):
        if export_type == "è‚¡ç¥¨å†å²æ•°æ®":
            if symbols and start_date < end_date:
                export_stock_data(symbols, start_date, end_date, export_format, services)
            else:
                st.error("è¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç å’Œæ—¥æœŸèŒƒå›´")
        
        elif export_type == "èµ„äº§ä¿¡æ¯":
            if symbols:
                export_asset_info(symbols, export_format, services)
            else:
                st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç ")
        
        elif export_type == "è‡ªé€‰è‚¡åˆ—è¡¨":
            export_watchlist(export_format)
    
    # å¯¼å‡ºå†å²
    st.markdown("---")
    st.subheader("ğŸ“ å¯¼å‡ºå†å²")
    display_export_history()

def export_stock_data(symbols, start_date, end_date, export_format, services):
    """å¯¼å‡ºè‚¡ç¥¨å†å²æ•°æ®"""

    try:
        mode = services.get('mode', 'unknown')
        start_date_str = start_date.strftime('%Y%m%d')
        end_date_str = end_date.strftime('%Y%m%d')

        all_data = []

        # è¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()

        for idx, symbol in enumerate(symbols):
            status_text.text(f"æ­£åœ¨è·å– {symbol} çš„æ•°æ®...")

            try:
                if mode == 'full':
                    # å®Œæ•´æ¨¡å¼ï¼šä½¿ç”¨stock_service
                    stock_data = services['stock_service'].get_stock_data(
                        symbol=symbol,
                        start_date=start_date_str,
                        end_date=end_date_str
                    )

                    if stock_data is not None and not stock_data.empty:
                        df = stock_data.copy()
                        df['symbol'] = symbol

                        # è·å–è‚¡ç¥¨åç§°
                        try:
                            asset_info, metadata = services['asset_service'].get_or_create_asset(symbol)
                            stock_name = asset_info.name if asset_info else f'è‚¡ç¥¨{symbol}'
                            df['name'] = stock_name
                        except:
                            df['name'] = f'è‚¡ç¥¨{symbol}'

                        all_data.append(df)

                elif mode == 'cloud':
                    # äº‘ç«¯æ¨¡å¼ï¼šç›´æ¥æŸ¥è¯¢SQLiteæ•°æ®åº“
                    import sqlite3
                    conn = sqlite3.connect(services['db_path'])

                    # æŸ¥è¯¢è‚¡ç¥¨æ•°æ®
                    query = """
                    SELECT a.symbol, a.name, d.date, d.open, d.high, d.low, d.close, d.volume, d.turnover
                    FROM daily_stock_data d
                    JOIN assets a ON d.asset_id = a.asset_id
                    WHERE a.symbol = ? AND d.date BETWEEN ? AND ?
                    ORDER BY d.date
                    """

                    df = pd.read_sql_query(query, conn, params=(symbol, start_date, end_date))
                    conn.close()

                    if not df.empty:
                        # æ ¼å¼åŒ–æ—¥æœŸ
                        df['trade_date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')
                        all_data.append(df)

                else:
                    # æœ€å°æ¨¡å¼ï¼šåˆ›å»ºç¤ºä¾‹æ•°æ®
                    df = pd.DataFrame({
                        'symbol': [symbol],
                        'name': [f'è‚¡ç¥¨{symbol}'],
                        'trade_date': [start_date.strftime('%Y-%m-%d')],
                        'open': [0.0],
                        'high': [0.0],
                        'low': [0.0],
                        'close': [0.0],
                        'volume': [0]
                    })
                    all_data.append(df)

            except Exception as e:
                st.warning(f"è·å– {symbol} æ•°æ®å¤±è´¥: {str(e)}")

            progress_bar.progress((idx + 1) / len(symbols))
        
        status_text.text("æ•°æ®è·å–å®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆæ–‡ä»¶...")
        
        if all_data:
            # åˆå¹¶æ‰€æœ‰æ•°æ®
            combined_df = pd.concat(all_data, ignore_index=True)
            
            # é‡æ–°æ’åˆ—åˆ—é¡ºåº
            columns_order = ['symbol', 'name', 'trade_date', 'open', 'high', 'low', 'close', 'volume']
            if 'turnover' in combined_df.columns:
                columns_order.append('turnover')
            
            combined_df = combined_df[[col for col in columns_order if col in combined_df.columns]]
            
            # é‡å‘½ååˆ—
            column_names = {
                'symbol': 'è‚¡ç¥¨ä»£ç ',
                'name': 'è‚¡ç¥¨åç§°',
                'trade_date': 'æ—¥æœŸ',
                'open': 'å¼€ç›˜ä»·',
                'high': 'æœ€é«˜ä»·',
                'low': 'æœ€ä½ä»·',
                'close': 'æ”¶ç›˜ä»·',
                'volume': 'æˆäº¤é‡',
                'turnover': 'æˆäº¤é¢'
            }
            combined_df = combined_df.rename(columns=column_names)
            
            # ç”Ÿæˆæ–‡ä»¶
            filename = f"è‚¡ç¥¨å†å²æ•°æ®_{start_date_str}_{end_date_str}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            if export_format == "CSV":
                csv_data = combined_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½CSVæ–‡ä»¶",
                    data=csv_data,
                    file_name=f"{filename}.csv",
                    mime="text/csv"
                )
            
            elif export_format == "Excel":
                if EXCEL_SUPPORT:
                    excel_buffer = io.BytesIO()
                    try:
                        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                            combined_df.to_excel(writer, sheet_name='è‚¡ç¥¨æ•°æ®', index=False)

                            # æ·»åŠ æ±‡æ€»ä¿¡æ¯
                            summary_df = pd.DataFrame({
                                'å¯¼å‡ºä¿¡æ¯': ['å¯¼å‡ºæ—¶é—´', 'æ•°æ®èŒƒå›´', 'è‚¡ç¥¨æ•°é‡', 'è®°å½•æ€»æ•°'],
                                'å€¼': [
                                    datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                                    f"{start_date} è‡³ {end_date}",
                                    len(symbols),
                                    len(combined_df)
                                ]
                            })
                            summary_df.to_excel(writer, sheet_name='å¯¼å‡ºä¿¡æ¯', index=False)

                        excel_data = excel_buffer.getvalue()
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½Excelæ–‡ä»¶",
                            data=excel_data,
                            file_name=f"{filename}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    except Exception as e:
                        st.error(f"Excelå¯¼å‡ºå¤±è´¥: {e}")
                        st.info("è¯·å°è¯•ä½¿ç”¨CSVæ ¼å¼")
                        return
                else:
                    st.error("Excelå¯¼å‡ºéœ€è¦å®‰è£…openpyxlåº“ï¼Œè¯·ä½¿ç”¨CSVæ ¼å¼")
                    return
            
            # æ˜¾ç¤ºé¢„è§ˆ
            st.success(f"âœ… å¯¼å‡ºå®Œæˆï¼å…± {len(combined_df)} æ¡è®°å½•")
            
            st.markdown("### ğŸ“Š æ•°æ®é¢„è§ˆ")
            st.dataframe(combined_df.head(10), use_container_width=True)
            
            # ä¿å­˜å¯¼å‡ºè®°å½•
            save_export_record("è‚¡ç¥¨å†å²æ•°æ®", len(symbols), len(combined_df), export_format)
        
        else:
            st.error("âŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
    
    except Exception as e:
        st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
        import traceback
        st.code(traceback.format_exc())

def export_asset_info(symbols, export_format, services):
    """å¯¼å‡ºèµ„äº§ä¿¡æ¯"""

    try:
        mode = services.get('mode', 'unknown')
        asset_data = []

        # è¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()

        for idx, symbol in enumerate(symbols):
            status_text.text(f"æ­£åœ¨è·å– {symbol} çš„èµ„äº§ä¿¡æ¯...")

            try:
                if mode == 'full':
                    # å®Œæ•´æ¨¡å¼ï¼šä½¿ç”¨asset_service
                    asset_info, metadata = services['asset_service'].get_or_create_asset(symbol)

                    if asset_info:
                        asset_dict = {
                            'symbol': asset_info.symbol,
                            'name': asset_info.name,
                            'asset_type': asset_info.asset_type,
                            'exchange': asset_info.exchange,
                            'industry': asset_info.industry,
                            'data_source': asset_info.data_source,
                            'last_updated': asset_info.last_updated.strftime('%Y-%m-%d %H:%M:%S') if asset_info.last_updated else None
                        }
                        asset_data.append(asset_dict)

                elif mode == 'cloud':
                    # äº‘ç«¯æ¨¡å¼ï¼šç›´æ¥æŸ¥è¯¢SQLiteæ•°æ®åº“
                    import sqlite3
                    conn = sqlite3.connect(services['db_path'])

                    query = """
                    SELECT symbol, name, asset_type, exchange, industry, data_source, last_updated
                    FROM assets
                    WHERE symbol = ?
                    """

                    cursor = conn.cursor()
                    cursor.execute(query, (symbol,))
                    result = cursor.fetchone()

                    if result:
                        asset_dict = {
                            'symbol': result[0],
                            'name': result[1],
                            'asset_type': result[2],
                            'exchange': result[3],
                            'industry': result[4],
                            'data_source': result[5],
                            'last_updated': result[6]
                        }
                        asset_data.append(asset_dict)

                    conn.close()

                else:
                    # æœ€å°æ¨¡å¼ï¼šåˆ›å»ºåŸºæœ¬ä¿¡æ¯
                    asset_dict = {
                        'symbol': symbol,
                        'name': f'è‚¡ç¥¨{symbol}',
                        'asset_type': 'è‚¡ç¥¨',
                        'exchange': 'N/A',
                        'industry': 'N/A',
                        'data_source': 'N/A',
                        'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    }
                    asset_data.append(asset_dict)

            except Exception as e:
                st.warning(f"è·å– {symbol} èµ„äº§ä¿¡æ¯å¤±è´¥: {str(e)}")

            progress_bar.progress((idx + 1) / len(symbols))

        status_text.text("æ•°æ®è·å–å®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆæ–‡ä»¶...")

        if asset_data:
            df = pd.DataFrame(asset_data)

            # é‡å‘½ååˆ—
            column_names = {
                'symbol': 'è‚¡ç¥¨ä»£ç ',
                'name': 'è‚¡ç¥¨åç§°',
                'asset_type': 'èµ„äº§ç±»å‹',
                'exchange': 'äº¤æ˜“æ‰€',
                'industry': 'è¡Œä¸š',
                'data_source': 'æ•°æ®æ¥æº',
                'last_updated': 'æœ€åæ›´æ–°æ—¶é—´'
            }

            # åªä¿ç•™å­˜åœ¨çš„åˆ—
            df = df.rename(columns={k: v for k, v in column_names.items() if k in df.columns})

            # ç”Ÿæˆæ–‡ä»¶
            filename = f"èµ„äº§ä¿¡æ¯_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

            if export_format == "CSV":
                csv_data = df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½CSVæ–‡ä»¶",
                    data=csv_data,
                    file_name=f"{filename}.csv",
                    mime="text/csv"
                )

            elif export_format == "Excel":
                if EXCEL_SUPPORT:
                    excel_buffer = io.BytesIO()
                    try:
                        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                            df.to_excel(writer, sheet_name='èµ„äº§ä¿¡æ¯', index=False)

                        excel_data = excel_buffer.getvalue()
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½Excelæ–‡ä»¶",
                            data=excel_data,
                            file_name=f"{filename}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    except Exception as e:
                        st.error(f"Excelå¯¼å‡ºå¤±è´¥: {e}")
                        st.info("è¯·å°è¯•ä½¿ç”¨CSVæ ¼å¼")
                        return
                else:
                    st.error("Excelå¯¼å‡ºéœ€è¦å®‰è£…openpyxlåº“ï¼Œè¯·ä½¿ç”¨CSVæ ¼å¼")
                    return

            # æ˜¾ç¤ºé¢„è§ˆ
            st.success(f"âœ… å¯¼å‡ºå®Œæˆï¼å…± {len(df)} æ¡è®°å½•")

            st.markdown("### ğŸ“Š æ•°æ®é¢„è§ˆ")
            st.dataframe(df, use_container_width=True)

            # ä¿å­˜å¯¼å‡ºè®°å½•
            save_export_record("èµ„äº§ä¿¡æ¯", len(symbols), len(df), export_format)

        else:
            st.error("âŒ æœªè·å–åˆ°ä»»ä½•èµ„äº§ä¿¡æ¯")

    except Exception as e:
        st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")

def export_watchlist(export_format):
    """å¯¼å‡ºè‡ªé€‰è‚¡åˆ—è¡¨"""

    try:
        # åŠ è½½è‡ªé€‰è‚¡æ•°æ®
        watchlist_file = current_dir / "data" / "watchlist.json"

        if watchlist_file.exists():
            with open(watchlist_file, 'r', encoding='utf-8') as f:
                watchlist = json.load(f)
        else:
            watchlist = {}

        if watchlist:
            # è½¬æ¢ä¸ºDataFrame
            data = []
            for symbol, info in watchlist.items():
                data.append({
                    'è‚¡ç¥¨ä»£ç ': symbol,
                    'è‚¡ç¥¨åç§°': info['name'],
                    'æ·»åŠ æ—¥æœŸ': info['added_date']
                })

            df = pd.DataFrame(data)

            # ç”Ÿæˆæ–‡ä»¶
            filename = f"è‡ªé€‰è‚¡åˆ—è¡¨_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

            if export_format == "CSV":
                csv_data = df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½CSVæ–‡ä»¶",
                    data=csv_data,
                    file_name=f"{filename}.csv",
                    mime="text/csv"
                )

            elif export_format == "Excel":
                if EXCEL_SUPPORT:
                    excel_buffer = io.BytesIO()
                    try:
                        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                            df.to_excel(writer, sheet_name='è‡ªé€‰è‚¡', index=False)

                        excel_data = excel_buffer.getvalue()
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½Excelæ–‡ä»¶",
                            data=excel_data,
                            file_name=f"{filename}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    except Exception as e:
                        st.error(f"Excelå¯¼å‡ºå¤±è´¥: {e}")
                        st.info("è¯·å°è¯•ä½¿ç”¨CSVæ ¼å¼")
                        return
                else:
                    st.error("Excelå¯¼å‡ºéœ€è¦å®‰è£…openpyxlåº“ï¼Œè¯·ä½¿ç”¨CSVæ ¼å¼")
                    return

            # æ˜¾ç¤ºé¢„è§ˆ
            st.success(f"âœ… å¯¼å‡ºå®Œæˆï¼å…± {len(df)} åªè‡ªé€‰è‚¡")

            st.markdown("### ğŸ“Š æ•°æ®é¢„è§ˆ")
            st.dataframe(df, use_container_width=True)

            # ä¿å­˜å¯¼å‡ºè®°å½•
            save_export_record("è‡ªé€‰è‚¡åˆ—è¡¨", 1, len(df), export_format)

        else:
            st.info("æš‚æ— è‡ªé€‰è‚¡æ•°æ®å¯å¯¼å‡º")

    except Exception as e:
        st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")

def save_export_record(data_type, symbol_count, record_count, export_format):
    """ä¿å­˜å¯¼å‡ºè®°å½•"""
    try:
        export_history_file = current_dir / "data" / "export_history.json"

        # åŠ è½½ç°æœ‰è®°å½•
        if export_history_file.exists():
            with open(export_history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)
        else:
            history = []

        # æ·»åŠ æ–°è®°å½•
        new_record = {
            "timestamp": datetime.now().isoformat(),
            "data_type": data_type,
            "symbol_count": symbol_count,
            "record_count": record_count,
            "export_format": export_format
        }

        history.append(new_record)

        # åªä¿ç•™æœ€è¿‘50æ¡è®°å½•
        history = history[-50:]

        # ä¿å­˜è®°å½•
        export_history_file.parent.mkdir(exist_ok=True)
        with open(export_history_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)

    except Exception as e:
        st.warning(f"ä¿å­˜å¯¼å‡ºè®°å½•å¤±è´¥: {str(e)}")

def display_export_history():
    """æ˜¾ç¤ºå¯¼å‡ºå†å²"""
    try:
        export_history_file = current_dir / "data" / "export_history.json"

        if export_history_file.exists():
            with open(export_history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)

            if history:
                # è½¬æ¢ä¸ºDataFrame
                df = pd.DataFrame(history)
                df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%Y-%m-%d %H:%M:%S')

                # é‡å‘½ååˆ—
                df = df.rename(columns={
                    'timestamp': 'å¯¼å‡ºæ—¶é—´',
                    'data_type': 'æ•°æ®ç±»å‹',
                    'symbol_count': 'è‚¡ç¥¨æ•°é‡',
                    'record_count': 'è®°å½•æ•°é‡',
                    'export_format': 'å¯¼å‡ºæ ¼å¼'
                })

                # æŒ‰æ—¶é—´å€’åºæ’åˆ—
                df = df.sort_values('å¯¼å‡ºæ—¶é—´', ascending=False)

                st.dataframe(df, use_container_width=True, hide_index=True)
            else:
                st.info("æš‚æ— å¯¼å‡ºå†å²")
        else:
            st.info("æš‚æ— å¯¼å‡ºå†å²")

    except Exception as e:
        st.error(f"åŠ è½½å¯¼å‡ºå†å²å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main()

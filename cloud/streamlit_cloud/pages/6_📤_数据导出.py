"""
æ•°æ®å¯¼å‡ºé¡µé¢ - äº‘ç«¯ç‰ˆæœ¬

æä¾›è‚¡ç¥¨æ•°æ®çš„å¯¼å‡ºåŠŸèƒ½ï¼Œæ”¯æŒCSVã€Excelæ ¼å¼ï¼Œå¯è‡ªå®šä¹‰å¯¼å‡ºèŒƒå›´å’Œæ ¼å¼ã€‚
"""

import streamlit as st
import pandas as pd
import io
from datetime import datetime, date, timedelta
import sys
import json
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent.parent
src_dir = current_dir / "src"
sys.path.insert(0, str(src_dir))

# å¯¼å…¥å·¥å…·ç»„ä»¶
try:
    from utils.config import config
    from utils.stock_validator import validate_stock_code, get_stock_recommendations
    ADVANCED_FEATURES = True
except ImportError:
    ADVANCED_FEATURES = False

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°æ®å¯¼å‡º - QuantDB Cloud",
    page_icon="ğŸ“¤",
    layout="wide"
)

@st.cache_resource
def init_services():
    """åˆå§‹åŒ–æœåŠ¡å®ä¾‹"""
    try:
        from services.stock_data_service import StockDataService
        from services.asset_info_service import AssetInfoService
        from cache.akshare_adapter import AKShareAdapter
        from api.database import get_db

        db_session = next(get_db())
        akshare_adapter = AKShareAdapter()
        
        return {
            'stock_service': StockDataService(db_session, akshare_adapter),
            'asset_service': AssetInfoService(db_session),
            'db_session': db_session
        }
    except Exception as e:
        st.error(f"æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

def main():
    """ä¸»é¡µé¢å‡½æ•°"""
    
    # é¡µé¢æ ‡é¢˜
    st.title("ğŸ“¤ æ•°æ®å¯¼å‡º")
    st.markdown("å¯¼å‡ºè‚¡ç¥¨æ•°æ®ã€èµ„äº§ä¿¡æ¯å’Œè‡ªé€‰è‚¡åˆ—è¡¨")
    st.markdown("---")
    
    # åˆå§‹åŒ–æœåŠ¡
    services = init_services()
    if not services:
        st.error("âŒ æœåŠ¡åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•")
        return
    
    # å¯¼å‡ºé€‰é¡¹
    st.subheader("ğŸ“‹ å¯¼å‡ºé…ç½®")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # æ•°æ®ç±»å‹é€‰æ‹©
        export_type = st.selectbox(
            "å¯¼å‡ºæ•°æ®ç±»å‹",
            ["è‚¡ç¥¨å†å²æ•°æ®", "èµ„äº§ä¿¡æ¯", "è‡ªé€‰è‚¡åˆ—è¡¨"],
            help="é€‰æ‹©è¦å¯¼å‡ºçš„æ•°æ®ç±»å‹"
        )
        
        # å¯¼å‡ºæ ¼å¼
        export_format = st.selectbox(
            "å¯¼å‡ºæ ¼å¼",
            ["CSV", "Excel"],
            help="é€‰æ‹©å¯¼å‡ºæ–‡ä»¶æ ¼å¼"
        )
    
    with col2:
        # è‚¡ç¥¨ä»£ç è¾“å…¥ï¼ˆä»…å¯¹è‚¡ç¥¨æ•°æ®æœ‰æ•ˆï¼‰
        if export_type in ["è‚¡ç¥¨å†å²æ•°æ®", "èµ„äº§ä¿¡æ¯"]:
            symbols_input = st.text_area(
                "è‚¡ç¥¨ä»£ç ",
                value="600000\n000001\n600519",
                help="æ¯è¡Œè¾“å…¥ä¸€ä¸ªè‚¡ç¥¨ä»£ç ï¼Œæ”¯æŒæ‰¹é‡å¯¼å‡º",
                height=100
            )
            
            # è§£æè‚¡ç¥¨ä»£ç 
            symbols = [s.strip() for s in symbols_input.split('\n') if s.strip()]
            
            # éªŒè¯è‚¡ç¥¨ä»£ç 
            valid_symbols = []
            for symbol in symbols:
                if ADVANCED_FEATURES:
                    validation = validate_stock_code(symbol)
                    if validation['is_valid']:
                        valid_symbols.append(symbol)
                else:
                    if config.validate_symbol(symbol):
                        valid_symbols.append(config.normalize_symbol(symbol))
            
            symbols = valid_symbols
            
            if symbols:
                st.success(f"âœ… æœ‰æ•ˆè‚¡ç¥¨ä»£ç : {len(symbols)}ä¸ª")
                st.write("è‚¡ç¥¨åˆ—è¡¨:", ", ".join(symbols))
            else:
                st.error("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç ")
        
        # æ—¥æœŸèŒƒå›´ï¼ˆä»…å¯¹å†å²æ•°æ®æœ‰æ•ˆï¼‰
        if export_type == "è‚¡ç¥¨å†å²æ•°æ®":
            st.markdown("**æ—¥æœŸèŒƒå›´**")
            
            col_start, col_end = st.columns(2)
            with col_start:
                start_date = st.date_input(
                    "å¼€å§‹æ—¥æœŸ",
                    value=date.today() - timedelta(days=30),
                    max_value=date.today()
                )
            
            with col_end:
                end_date = st.date_input(
                    "ç»“æŸæ—¥æœŸ",
                    value=date.today(),
                    max_value=date.today()
                )
    
    # å¯¼å‡ºæŒ‰é’®
    st.markdown("---")
    
    if st.button("ğŸš€ å¼€å§‹å¯¼å‡º", type="primary", use_container_width=True):
        if export_type == "è‚¡ç¥¨å†å²æ•°æ®":
            if symbols and start_date < end_date:
                export_stock_data(symbols, start_date, end_date, export_format, services)
            else:
                st.error("è¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç å’Œæ—¥æœŸèŒƒå›´")
        
        elif export_type == "èµ„äº§ä¿¡æ¯":
            if symbols:
                export_asset_info(symbols, export_format, services)
            else:
                st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç ")
        
        elif export_type == "è‡ªé€‰è‚¡åˆ—è¡¨":
            export_watchlist(export_format)
    
    # å¯¼å‡ºå†å²
    st.markdown("---")
    st.subheader("ğŸ“ å¯¼å‡ºå†å²")
    display_export_history()

def export_stock_data(symbols, start_date, end_date, export_format, services):
    """å¯¼å‡ºè‚¡ç¥¨å†å²æ•°æ®"""
    
    try:
        start_date_str = start_date.strftime('%Y%m%d')
        end_date_str = end_date.strftime('%Y%m%d')
        
        all_data = []
        
        # è¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for idx, symbol in enumerate(symbols):
            status_text.text(f"æ­£åœ¨è·å– {symbol} çš„æ•°æ®...")
            
            try:
                # è·å–è‚¡ç¥¨æ•°æ®
                stock_data = services['stock_service'].get_stock_data(
                    symbol=symbol,
                    start_date=start_date_str,
                    end_date=end_date_str
                )
                
                if stock_data is not None and not stock_data.empty:
                    df = stock_data.copy()
                    df['symbol'] = symbol
                    
                    # è·å–è‚¡ç¥¨åç§°
                    try:
                        asset_info, metadata = services['asset_service'].get_or_create_asset(symbol)
                        stock_name = asset_info.name if asset_info else f'è‚¡ç¥¨{symbol}'
                        df['name'] = stock_name
                    except:
                        df['name'] = f'è‚¡ç¥¨{symbol}'
                    
                    # ç¡®ä¿æ—¥æœŸåˆ—æ ¼å¼æ­£ç¡®
                    if 'date' in df.columns:
                        df['trade_date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')
                    elif 'trade_date' in df.columns:
                        df['trade_date'] = pd.to_datetime(df['trade_date']).dt.strftime('%Y-%m-%d')
                    
                    all_data.append(df)
                
            except Exception as e:
                st.warning(f"è·å– {symbol} æ•°æ®å¤±è´¥: {str(e)}")
            
            progress_bar.progress((idx + 1) / len(symbols))
        
        status_text.text("æ•°æ®è·å–å®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆæ–‡ä»¶...")
        
        if all_data:
            # åˆå¹¶æ‰€æœ‰æ•°æ®
            combined_df = pd.concat(all_data, ignore_index=True)
            
            # é‡æ–°æ’åˆ—åˆ—é¡ºåº
            columns_order = ['symbol', 'name', 'trade_date', 'open', 'high', 'low', 'close', 'volume']
            if 'turnover' in combined_df.columns:
                columns_order.append('turnover')
            
            combined_df = combined_df[[col for col in columns_order if col in combined_df.columns]]
            
            # é‡å‘½ååˆ—
            column_names = {
                'symbol': 'è‚¡ç¥¨ä»£ç ',
                'name': 'è‚¡ç¥¨åç§°',
                'trade_date': 'æ—¥æœŸ',
                'open': 'å¼€ç›˜ä»·',
                'high': 'æœ€é«˜ä»·',
                'low': 'æœ€ä½ä»·',
                'close': 'æ”¶ç›˜ä»·',
                'volume': 'æˆäº¤é‡',
                'turnover': 'æˆäº¤é¢'
            }
            combined_df = combined_df.rename(columns=column_names)
            
            # ç”Ÿæˆæ–‡ä»¶
            filename = f"è‚¡ç¥¨å†å²æ•°æ®_{start_date_str}_{end_date_str}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            if export_format == "CSV":
                csv_data = combined_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½CSVæ–‡ä»¶",
                    data=csv_data,
                    file_name=f"{filename}.csv",
                    mime="text/csv"
                )
            
            elif export_format == "Excel":
                excel_buffer = io.BytesIO()
                try:
                    with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                        combined_df.to_excel(writer, sheet_name='è‚¡ç¥¨æ•°æ®', index=False)
                        
                        # æ·»åŠ æ±‡æ€»ä¿¡æ¯
                        summary_df = pd.DataFrame({
                            'å¯¼å‡ºä¿¡æ¯': ['å¯¼å‡ºæ—¶é—´', 'æ•°æ®èŒƒå›´', 'è‚¡ç¥¨æ•°é‡', 'è®°å½•æ€»æ•°'],
                            'å€¼': [
                                datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                                f"{start_date} è‡³ {end_date}",
                                len(symbols),
                                len(combined_df)
                            ]
                        })
                        summary_df.to_excel(writer, sheet_name='å¯¼å‡ºä¿¡æ¯', index=False)
                    
                    excel_data = excel_buffer.getvalue()
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½Excelæ–‡ä»¶",
                        data=excel_data,
                        file_name=f"{filename}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                except ImportError:
                    st.error("Excelå¯¼å‡ºéœ€è¦å®‰è£…openpyxlåº“ï¼Œè¯·ä½¿ç”¨CSVæ ¼å¼")
                    return
            
            # æ˜¾ç¤ºé¢„è§ˆ
            st.success(f"âœ… å¯¼å‡ºå®Œæˆï¼å…± {len(combined_df)} æ¡è®°å½•")
            
            st.markdown("### ğŸ“Š æ•°æ®é¢„è§ˆ")
            st.dataframe(combined_df.head(10), use_container_width=True)
            
            # ä¿å­˜å¯¼å‡ºè®°å½•
            save_export_record("è‚¡ç¥¨å†å²æ•°æ®", len(symbols), len(combined_df), export_format)
        
        else:
            st.error("âŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
    
    except Exception as e:
        st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
        import traceback
        st.code(traceback.format_exc())

def export_asset_info(symbols, export_format, services):
    """å¯¼å‡ºèµ„äº§ä¿¡æ¯"""

    try:
        asset_data = []

        # è¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()

        for idx, symbol in enumerate(symbols):
            status_text.text(f"æ­£åœ¨è·å– {symbol} çš„èµ„äº§ä¿¡æ¯...")

            try:
                asset_info, metadata = services['asset_service'].get_or_create_asset(symbol)

                if asset_info:
                    asset_dict = {
                        'symbol': asset_info.symbol,
                        'name': asset_info.name,
                        'asset_type': asset_info.asset_type,
                        'exchange': asset_info.exchange,
                        'industry': asset_info.industry,
                        'data_source': asset_info.data_source,
                        'last_updated': asset_info.last_updated.strftime('%Y-%m-%d %H:%M:%S') if asset_info.last_updated else None
                    }
                    asset_data.append(asset_dict)

            except Exception as e:
                st.warning(f"è·å– {symbol} èµ„äº§ä¿¡æ¯å¤±è´¥: {str(e)}")

            progress_bar.progress((idx + 1) / len(symbols))

        status_text.text("æ•°æ®è·å–å®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆæ–‡ä»¶...")

        if asset_data:
            df = pd.DataFrame(asset_data)

            # é‡å‘½ååˆ—
            column_names = {
                'symbol': 'è‚¡ç¥¨ä»£ç ',
                'name': 'è‚¡ç¥¨åç§°',
                'asset_type': 'èµ„äº§ç±»å‹',
                'exchange': 'äº¤æ˜“æ‰€',
                'industry': 'è¡Œä¸š',
                'data_source': 'æ•°æ®æ¥æº',
                'last_updated': 'æœ€åæ›´æ–°æ—¶é—´'
            }

            # åªä¿ç•™å­˜åœ¨çš„åˆ—
            df = df.rename(columns={k: v for k, v in column_names.items() if k in df.columns})

            # ç”Ÿæˆæ–‡ä»¶
            filename = f"èµ„äº§ä¿¡æ¯_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

            if export_format == "CSV":
                csv_data = df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½CSVæ–‡ä»¶",
                    data=csv_data,
                    file_name=f"{filename}.csv",
                    mime="text/csv"
                )

            elif export_format == "Excel":
                excel_buffer = io.BytesIO()
                try:
                    with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                        df.to_excel(writer, sheet_name='èµ„äº§ä¿¡æ¯', index=False)

                    excel_data = excel_buffer.getvalue()
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½Excelæ–‡ä»¶",
                        data=excel_data,
                        file_name=f"{filename}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                except ImportError:
                    st.error("Excelå¯¼å‡ºéœ€è¦å®‰è£…openpyxlåº“ï¼Œè¯·ä½¿ç”¨CSVæ ¼å¼")
                    return

            # æ˜¾ç¤ºé¢„è§ˆ
            st.success(f"âœ… å¯¼å‡ºå®Œæˆï¼å…± {len(df)} æ¡è®°å½•")

            st.markdown("### ğŸ“Š æ•°æ®é¢„è§ˆ")
            st.dataframe(df, use_container_width=True)

            # ä¿å­˜å¯¼å‡ºè®°å½•
            save_export_record("èµ„äº§ä¿¡æ¯", len(symbols), len(df), export_format)

        else:
            st.error("âŒ æœªè·å–åˆ°ä»»ä½•èµ„äº§ä¿¡æ¯")

    except Exception as e:
        st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")

def export_watchlist(export_format):
    """å¯¼å‡ºè‡ªé€‰è‚¡åˆ—è¡¨"""

    try:
        # åŠ è½½è‡ªé€‰è‚¡æ•°æ®
        watchlist_file = current_dir / "data" / "watchlist.json"

        if watchlist_file.exists():
            with open(watchlist_file, 'r', encoding='utf-8') as f:
                watchlist = json.load(f)
        else:
            watchlist = {}

        if watchlist:
            # è½¬æ¢ä¸ºDataFrame
            data = []
            for symbol, info in watchlist.items():
                data.append({
                    'è‚¡ç¥¨ä»£ç ': symbol,
                    'è‚¡ç¥¨åç§°': info['name'],
                    'æ·»åŠ æ—¥æœŸ': info['added_date']
                })

            df = pd.DataFrame(data)

            # ç”Ÿæˆæ–‡ä»¶
            filename = f"è‡ªé€‰è‚¡åˆ—è¡¨_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

            if export_format == "CSV":
                csv_data = df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½CSVæ–‡ä»¶",
                    data=csv_data,
                    file_name=f"{filename}.csv",
                    mime="text/csv"
                )

            elif export_format == "Excel":
                excel_buffer = io.BytesIO()
                try:
                    with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                        df.to_excel(writer, sheet_name='è‡ªé€‰è‚¡', index=False)

                    excel_data = excel_buffer.getvalue()
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½Excelæ–‡ä»¶",
                        data=excel_data,
                        file_name=f"{filename}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                except ImportError:
                    st.error("Excelå¯¼å‡ºéœ€è¦å®‰è£…openpyxlåº“ï¼Œè¯·ä½¿ç”¨CSVæ ¼å¼")
                    return

            # æ˜¾ç¤ºé¢„è§ˆ
            st.success(f"âœ… å¯¼å‡ºå®Œæˆï¼å…± {len(df)} åªè‡ªé€‰è‚¡")

            st.markdown("### ğŸ“Š æ•°æ®é¢„è§ˆ")
            st.dataframe(df, use_container_width=True)

            # ä¿å­˜å¯¼å‡ºè®°å½•
            save_export_record("è‡ªé€‰è‚¡åˆ—è¡¨", 1, len(df), export_format)

        else:
            st.info("æš‚æ— è‡ªé€‰è‚¡æ•°æ®å¯å¯¼å‡º")

    except Exception as e:
        st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")

def save_export_record(data_type, symbol_count, record_count, export_format):
    """ä¿å­˜å¯¼å‡ºè®°å½•"""
    try:
        export_history_file = current_dir / "data" / "export_history.json"

        # åŠ è½½ç°æœ‰è®°å½•
        if export_history_file.exists():
            with open(export_history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)
        else:
            history = []

        # æ·»åŠ æ–°è®°å½•
        new_record = {
            "timestamp": datetime.now().isoformat(),
            "data_type": data_type,
            "symbol_count": symbol_count,
            "record_count": record_count,
            "export_format": export_format
        }

        history.append(new_record)

        # åªä¿ç•™æœ€è¿‘50æ¡è®°å½•
        history = history[-50:]

        # ä¿å­˜è®°å½•
        export_history_file.parent.mkdir(exist_ok=True)
        with open(export_history_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)

    except Exception as e:
        st.warning(f"ä¿å­˜å¯¼å‡ºè®°å½•å¤±è´¥: {str(e)}")

def display_export_history():
    """æ˜¾ç¤ºå¯¼å‡ºå†å²"""
    try:
        export_history_file = current_dir / "data" / "export_history.json"

        if export_history_file.exists():
            with open(export_history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)

            if history:
                # è½¬æ¢ä¸ºDataFrame
                df = pd.DataFrame(history)
                df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%Y-%m-%d %H:%M:%S')

                # é‡å‘½ååˆ—
                df = df.rename(columns={
                    'timestamp': 'å¯¼å‡ºæ—¶é—´',
                    'data_type': 'æ•°æ®ç±»å‹',
                    'symbol_count': 'è‚¡ç¥¨æ•°é‡',
                    'record_count': 'è®°å½•æ•°é‡',
                    'export_format': 'å¯¼å‡ºæ ¼å¼'
                })

                # æŒ‰æ—¶é—´å€’åºæ’åˆ—
                df = df.sort_values('å¯¼å‡ºæ—¶é—´', ascending=False)

                st.dataframe(df, use_container_width=True, hide_index=True)
            else:
                st.info("æš‚æ— å¯¼å‡ºå†å²")
        else:
            st.info("æš‚æ— å¯¼å‡ºå†å²")

    except Exception as e:
        st.error(f"åŠ è½½å¯¼å‡ºå†å²å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main()

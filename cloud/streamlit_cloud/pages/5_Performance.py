"""
Performance Monitoring Page - Cloud Version

Display system performance metrics, cache hit rates and response time monitoring.
"""

import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import time
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„ä»¥è®¿é—®coreæ¨¡å—
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent  # å›åˆ°QuantDBæ ¹ç›®å½•
sys.path.insert(0, str(project_root))

# å¯¼å…¥å·¥å…·ç»„ä»¶
try:
    import plotly.graph_objects as go
    import plotly.express as px
    ADVANCED_FEATURES = True
except ImportError:
    ADVANCED_FEATURES = False

# Detect running environment
CLOUD_MODE = True
try:
    # Detect if in Streamlit Cloud environment
    import os
    if 'STREAMLIT_SHARING' in os.environ or 'STREAMLIT_CLOUD' in os.environ:
        CLOUD_MODE = True
    else:
        # Test if core modules can be imported
        from core.services import StockDataService
        CLOUD_MODE = False
except Exception:
    CLOUD_MODE = True

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Performance - QuantDB",
    page_icon="ğŸ“Š",
    layout="wide"
)

@st.cache_resource
def init_services():
    """Initialize service instances - cloud optimized version"""
    try:
        if not CLOUD_MODE:
            # Full mode: use core modules
            from core.services import StockDataService, DatabaseCache
            from core.cache import AKShareAdapter
            from core.database import get_db

            db_session = next(get_db())
            akshare_adapter = AKShareAdapter()

            return {
                'stock_service': StockDataService(db_session, akshare_adapter),
                'cache_service': DatabaseCache(db_session),
                'db_session': db_session,
                'mode': 'full'
            }
        else:
            # Cloud mode: simplified service initialization
            import sqlite3
            from pathlib import Path

            current_dir = Path(__file__).parent
            db_path = current_dir / "database" / "stock_data.db"

            # Test SQLite connection
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()

            # Get basic statistics
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            tables = [row[0] for row in cursor.fetchall()]

            # Get asset count
            asset_count = 0
            data_count = 0
            if 'assets' in tables:
                cursor.execute("SELECT COUNT(*) FROM assets")
                asset_count = cursor.fetchone()[0]

            if 'daily_stock_data' in tables:
                cursor.execute("SELECT COUNT(*) FROM daily_stock_data")
                data_count = cursor.fetchone()[0]

            conn.close()

            return {
                'db_path': str(db_path),
                'tables': tables,
                'asset_count': asset_count,
                'data_count': data_count,
                'mode': 'cloud'
            }

    except Exception as e:
        st.error(f"Service initialization failed: {e}")
        # Return minimal service object to avoid page crash
        return {
            'mode': 'minimal',
            'error': str(e),
            'asset_count': 0,
            'data_count': 0
        }

def main():
    """ä¸»é¡µé¢å‡½æ•°"""
    
    # Page title
    st.title("âš¡ Performance Monitoring")
    st.markdown("Monitor system performance metrics, cache efficiency and response time")
    st.markdown("---")
    
    # Initialize services
    services = init_services()
    if not services:
        st.error("âŒ Service initialization failed, please refresh the page and try again")
        return

    # Display running mode
    mode = services.get('mode', 'unknown')
    if mode == 'full':
        st.info("ğŸ–¥ï¸ Running Mode: Full Mode (using core services)")
    elif mode == 'cloud':
        st.info("â˜ï¸ Running Mode: Cloud Mode (SQLite direct connection)")
    elif mode == 'minimal':
        st.warning("âš ï¸ Running Mode: Minimal Mode (limited functionality)")
        st.error(f"Initialization error: {services.get('error', 'Unknown error')}")

    # Control panel
    col1, col2, col3 = st.columns([2, 1, 1])

    with col1:
        st.markdown("### ğŸ“Š Real-time Performance Monitoring")

    with col2:
        auto_refresh = st.checkbox("Auto Refresh", value=False, help="Auto refresh data every 30 seconds")

    with col3:
        if st.button("ğŸ”„ Refresh Now", use_container_width=True):
            st.session_state.force_refresh = True
            # Clear cache to get latest data
            init_services.clear()
    
    # è‡ªåŠ¨åˆ·æ–°é€»è¾‘
    if auto_refresh:
        time.sleep(30)
        st.rerun()
    
    # Display performance monitoring data
    display_performance_monitoring(services)

def display_performance_monitoring(services):
    """Display performance monitoring data"""

    try:
        mode = services.get('mode', 'unknown')

        # Get cache statistics
        with st.spinner("Getting performance data..."):
            if mode == 'full':
                # Full mode: use cache_service
                cache_stats = services['cache_service'].get_stats()
            elif mode == 'cloud':
                # Cloud mode: construct statistics data
                cache_stats = {
                    'total_assets': services.get('asset_count', 0),
                    'total_data_points': services.get('data_count', 0),
                    'date_range': {'min_date': 'N/A', 'max_date': 'N/A'},
                    'top_assets': []
                }

                # Try to get more detailed statistics
                try:
                    import sqlite3
                    conn = sqlite3.connect(services['db_path'])
                    cursor = conn.cursor()

                    # è·å–æ—¥æœŸèŒƒå›´
                    if 'daily_stock_data' in services.get('tables', []):
                        cursor.execute("SELECT MIN(date), MAX(date) FROM daily_stock_data")
                        date_range = cursor.fetchone()
                        if date_range[0] and date_range[1]:
                            cache_stats['date_range'] = {
                                'min_date': str(date_range[0]),
                                'max_date': str(date_range[1])
                            }

                    conn.close()
                except Exception as e:
                    st.warning(f"è·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            else:
                # æœ€å°æ¨¡å¼ï¼šä½¿ç”¨é»˜è®¤å€¼
                cache_stats = {
                    'total_assets': 0,
                    'total_data_points': 0,
                    'date_range': {'min_date': 'N/A', 'max_date': 'N/A'},
                    'top_assets': []
                }
        
        # Core performance metrics
        st.subheader("ğŸš€ Core Performance Metrics")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            # Test database response time
            start_time = time.time()

            if mode == 'full':
                # Full mode: use SQLAlchemy
                from sqlalchemy import text
                test_query = services['db_session'].execute(text("SELECT COUNT(*) FROM assets")).scalar()
            elif mode == 'cloud':
                # Cloud mode: use SQLite direct connection
                import sqlite3
                conn = sqlite3.connect(services['db_path'])
                cursor = conn.cursor()
                cursor.execute("SELECT COUNT(*) FROM assets")
                test_query = cursor.fetchone()[0]
                conn.close()
            else:
                test_query = 0

            cache_response_time = (time.time() - start_time) * 1000

            st.metric(
                label="Database Response Time",
                value=f"{cache_response_time:.1f}ms",
                delta="Excellent" if cache_response_time < 50 else "Fast",
                help="Response time for getting data from SQLite database"
            )
        
        with col2:
            # æ¨¡æ‹ŸAKShareå“åº”æ—¶é—´
            akshare_response_time = 1200.0
            st.metric(
                label="AKShareå“åº”æ—¶é—´",
                value=f"{akshare_response_time:.1f}ms",
                help="ç›´æ¥ä»AKShareè·å–æ•°æ®çš„ä¼°è®¡å“åº”æ—¶é—´"
            )
        
        with col3:
            # è®¡ç®—æ€§èƒ½æå‡
            performance_improvement = ((akshare_response_time - cache_response_time) / akshare_response_time * 100)
            st.metric(
                label="æ€§èƒ½æå‡",
                value=f"{performance_improvement:.1f}%",
                delta="ä¼˜ç§€",
                help="æœ¬åœ°ç¼“å­˜ç›¸æ¯”AKShareç›´æ¥è°ƒç”¨çš„æ€§èƒ½æå‡"
            )
        
        with col4:
            # æ•°æ®è¦†ç›–ç‡
            total_assets = cache_stats.get('total_assets', 0)
            total_data_points = cache_stats.get('total_data_points', 0)
            coverage_rate = min(100, (total_data_points / 1000) * 100) if total_data_points > 0 else 0
            
            st.metric(
                label="æ•°æ®è¦†ç›–ç‡",
                value=f"{coverage_rate:.1f}%",
                delta="è‰¯å¥½" if coverage_rate > 50 else "å»ºè®¾ä¸­",
                help="æ•°æ®åº“ä¸­æ•°æ®çš„è¦†ç›–ç¨‹åº¦"
            )
        
        st.markdown("---")
        
        # æ€§èƒ½å¯¹æ¯”å›¾è¡¨
        if ADVANCED_FEATURES:
            st.subheader("ğŸ“Š æ€§èƒ½å¯¹æ¯”åˆ†æ")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("#### å“åº”æ—¶é—´å¯¹æ¯”")
                perf_chart = create_performance_comparison_chart(cache_response_time, akshare_response_time)
                st.plotly_chart(perf_chart, use_container_width=True)

            with col2:
                st.markdown("#### æ•°æ®è¦†ç›–åˆ†å¸ƒ")
                # æ¨¡æ‹Ÿç¼“å­˜å‘½ä¸­ç‡
                cache_hits = int(coverage_rate)
                cache_misses = 100 - cache_hits
                cache_pie = create_cache_hit_pie_chart(cache_hits, cache_misses)
                st.plotly_chart(cache_pie, use_container_width=True)
        else:
            st.info("ğŸ“Š å›¾è¡¨åŠŸèƒ½éœ€è¦plotlyæ”¯æŒï¼Œå½“å‰ä½¿ç”¨ç®€åŒ–æ˜¾ç¤ºæ¨¡å¼")
        
        # ç³»ç»Ÿèµ„æºç›‘æ§
        st.markdown("---")
        st.subheader("ğŸ’» ç³»ç»Ÿèµ„æºç›‘æ§")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            # è®¡ç®—æ•°æ®åº“å¤§å°ï¼ˆä¼°ç®—ï¼‰
            db_size = total_data_points * 0.1 / 1024  # ä¼°ç®—æ¯æ¡è®°å½•çº¦0.1KB
            st.metric(
                label="æ•°æ®åº“å¤§å°",
                value=f"{db_size:.1f} MB",
                help="SQLiteæ•°æ®åº“ä¼°ç®—å¤§å°"
            )
        
        with col2:
            st.metric(
                label="æ€»è®°å½•æ•°",
                value=f"{total_data_points:,}",
                help="æ•°æ®åº“ä¸­çš„å†å²æ•°æ®è®°å½•æ€»æ•°"
            )
        
        with col3:
            st.metric(
                label="ç¼“å­˜èµ„äº§æ•°",
                value=f"{total_assets:,}",
                help="å·²ç¼“å­˜çš„è‚¡ç¥¨èµ„äº§æ•°é‡"
            )
        
        with col4:
            # è®¡ç®—æ•°æ®å¯†åº¦
            data_density = total_data_points / total_assets if total_assets > 0 else 0
            st.metric(
                label="å¹³å‡æ•°æ®å¯†åº¦",
                value=f"{data_density:.0f}æ¡/è‚¡",
                help="æ¯åªè‚¡ç¥¨çš„å¹³å‡å†å²æ•°æ®è®°å½•æ•°"
            )
        
        # å®æ—¶æ€§èƒ½æµ‹è¯•
        st.markdown("---")
        st.subheader("ğŸ§ª å®æ—¶æ€§èƒ½æµ‹è¯•")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢", use_container_width=True):
                test_database_performance(services)
        
        with col2:
            if st.button("æµ‹è¯•æ•°æ®æŸ¥è¯¢æ€§èƒ½", use_container_width=True):
                test_data_query_performance(services)
        
        with col3:
            if st.button("æµ‹è¯•ç¼“å­˜æ€§èƒ½", use_container_width=True):
                test_cache_performance(services)
        
        # æ•°æ®åº“è¯¦ç»†ä¿¡æ¯
        st.markdown("---")
        st.subheader("ğŸ“ˆ æ•°æ®åº“è¯¦ç»†ä¿¡æ¯")
        
        if cache_stats:
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### ğŸ“Š æ•°æ®ç»Ÿè®¡")
                date_range = cache_stats.get('date_range', {})
                st.write(f"**æœ€æ—©æ•°æ®**: {date_range.get('min_date', 'N/A')}")
                st.write(f"**æœ€æ–°æ•°æ®**: {date_range.get('max_date', 'N/A')}")
                st.write(f"**æ€»èµ„äº§æ•°**: {total_assets:,}")
                st.write(f"**æ€»æ•°æ®ç‚¹**: {total_data_points:,}")
            
            with col2:
                st.markdown("#### ğŸ† çƒ­é—¨èµ„äº§")
                top_assets = cache_stats.get('top_assets', [])
                if top_assets:
                    for i, asset in enumerate(top_assets[:5], 1):
                        st.write(f"{i}. **{asset['symbol']}** - {asset['name']} ({asset['data_points']}æ¡)")
                else:
                    st.write("æš‚æ— æ•°æ®")
        
    except Exception as e:
        st.error(f"è·å–æ€§èƒ½æ•°æ®å¤±è´¥: {str(e)}")
        st.info("è¯·æ£€æŸ¥æ•°æ®åº“è¿æ¥çŠ¶æ€")

def test_database_performance(services):
    """æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½"""
    with st.spinner("æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½..."):
        try:
            mode = services.get('mode', 'unknown')
            times = []

            # è¿›è¡Œå¤šæ¬¡æµ‹è¯•å–å¹³å‡å€¼
            for i in range(5):
                start_time = time.time()

                if mode == 'full':
                    # å®Œæ•´æ¨¡å¼ï¼šä½¿ç”¨SQLAlchemy
                    from sqlalchemy import text
                    result = services['db_session'].execute(text("SELECT COUNT(*) FROM daily_stock_data")).scalar()
                elif mode == 'cloud':
                    # äº‘ç«¯æ¨¡å¼ï¼šä½¿ç”¨SQLiteç›´è¿
                    import sqlite3
                    conn = sqlite3.connect(services['db_path'])
                    cursor = conn.cursor()
                    cursor.execute("SELECT COUNT(*) FROM daily_stock_data")
                    result = cursor.fetchone()[0]
                    conn.close()
                else:
                    result = 0

                end_time = time.time()
                times.append((end_time - start_time) * 1000)

            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)

            st.success("âœ… æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½æµ‹è¯•å®Œæˆ")

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("å¹³å‡å“åº”æ—¶é—´", f"{avg_time:.1f}ms")
            with col2:
                st.metric("æœ€å¿«å“åº”æ—¶é—´", f"{min_time:.1f}ms")
            with col3:
                st.metric("æœ€æ…¢å“åº”æ—¶é—´", f"{max_time:.1f}ms")

        except Exception as e:
            st.error(f"æ•°æ®åº“æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {str(e)}")
            with st.expander("ğŸ” é”™è¯¯è¯¦æƒ…"):
                st.code(str(e))

def test_data_query_performance(services):
    """æµ‹è¯•æ•°æ®æŸ¥è¯¢æ€§èƒ½"""
    with st.spinner("æµ‹è¯•æ•°æ®æŸ¥è¯¢æ€§èƒ½..."):
        try:
            mode = services.get('mode', 'unknown')
            start_time = time.time()

            if mode == 'full':
                # å®Œæ•´æ¨¡å¼ï¼šä½¿ç”¨stock_service
                stock_data = services['stock_service'].get_stock_data("600000", "20240101", "20240105")
                record_count = len(stock_data) if stock_data is not None and not stock_data.empty else 0
            elif mode == 'cloud':
                # äº‘ç«¯æ¨¡å¼ï¼šç›´æ¥æŸ¥è¯¢æ•°æ®åº“
                import sqlite3
                conn = sqlite3.connect(services['db_path'])
                cursor = conn.cursor()

                # æŸ¥è¯¢600000çš„æ•°æ®
                cursor.execute("""
                    SELECT COUNT(*) FROM daily_stock_data d
                    JOIN assets a ON d.asset_id = a.asset_id
                    WHERE a.symbol = '600000' AND d.date BETWEEN '2024-01-01' AND '2024-01-05'
                """)
                record_count = cursor.fetchone()[0]
                conn.close()
            else:
                record_count = 0

            end_time = time.time()
            response_time = (end_time - start_time) * 1000

            st.success("âœ… æ•°æ®æŸ¥è¯¢æ€§èƒ½æµ‹è¯•å®Œæˆ")

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("å“åº”æ—¶é—´", f"{response_time:.1f}ms")
            with col2:
                st.metric("æ•°æ®è®°å½•æ•°", f"{record_count}")
            with col3:
                status = "ä¼˜ç§€" if response_time < 100 else "è‰¯å¥½" if response_time < 1000 else "éœ€ä¼˜åŒ–"
                st.metric("æ€§èƒ½ç­‰çº§", status)

        except Exception as e:
            st.error(f"æ•°æ®æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {str(e)}")
            with st.expander("ğŸ” é”™è¯¯è¯¦æƒ…"):
                st.code(str(e))

def test_cache_performance(services):
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
    with st.spinner("æµ‹è¯•ç¼“å­˜æ€§èƒ½..."):
        try:
            mode = services.get('mode', 'unknown')
            symbol = "600000"
            times = []

            for i in range(3):
                start_time = time.time()

                if mode == 'full':
                    # å®Œæ•´æ¨¡å¼ï¼šä½¿ç”¨stock_service
                    stock_data = services['stock_service'].get_stock_data(symbol, "20240101", "20240105")
                elif mode == 'cloud':
                    # äº‘ç«¯æ¨¡å¼ï¼šSQLiteæŸ¥è¯¢ï¼ˆæœ¬èº«å°±æ˜¯ç¼“å­˜ï¼‰
                    import sqlite3
                    conn = sqlite3.connect(services['db_path'])
                    cursor = conn.cursor()
                    cursor.execute("""
                        SELECT COUNT(*) FROM daily_stock_data d
                        JOIN assets a ON d.asset_id = a.asset_id
                        WHERE a.symbol = ? AND d.date BETWEEN '2024-01-01' AND '2024-01-05'
                    """, (symbol,))
                    result = cursor.fetchone()[0]
                    conn.close()
                else:
                    result = 0

                end_time = time.time()
                response_time = (end_time - start_time) * 1000
                times.append(response_time)

            avg_time = sum(times) / len(times)
            improvement = ((times[0] - times[-1]) / times[0] * 100) if times[0] > 0 else 0

            st.success("âœ… ç¼“å­˜æ€§èƒ½æµ‹è¯•å®Œæˆ")

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("å¹³å‡å“åº”æ—¶é—´", f"{avg_time:.1f}ms")
            with col2:
                st.metric("é¦–æ¬¡æŸ¥è¯¢", f"{times[0]:.1f}ms")
            with col3:
                st.metric("åç»­æŸ¥è¯¢", f"{times[-1]:.1f}ms")

            if improvement > 0:
                st.info(f"ğŸš€ ç¼“å­˜æ•ˆæœ: æ€§èƒ½æå‡ {improvement:.1f}%")
            elif mode == 'cloud':
                st.info("ğŸ’¾ SQLiteæ•°æ®åº“æœ¬èº«æä¾›äº†é«˜æ•ˆçš„æ•°æ®ç¼“å­˜")

        except Exception as e:
            st.error(f"ç¼“å­˜æ€§èƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
            with st.expander("ğŸ” é”™è¯¯è¯¦æƒ…"):
                st.code(str(e))

# ç®€åŒ–çš„å›¾è¡¨åˆ›å»ºå‡½æ•°
def create_performance_comparison_chart(cache_time, akshare_time):
    """åˆ›å»ºæ€§èƒ½å¯¹æ¯”å›¾è¡¨"""
    if not ADVANCED_FEATURES:
        return None

    try:
        import plotly.graph_objects as go

        fig = go.Figure(data=[
            go.Bar(name='SQLiteç¼“å­˜', x=['å“åº”æ—¶é—´'], y=[cache_time], marker_color='lightblue'),
            go.Bar(name='AKShareç›´è¿', x=['å“åº”æ—¶é—´'], y=[akshare_time], marker_color='lightcoral')
        ])

        fig.update_layout(
            title='å“åº”æ—¶é—´å¯¹æ¯” (æ¯«ç§’)',
            yaxis_title='å“åº”æ—¶é—´ (ms)',
            barmode='group',
            height=400
        )

        return fig
    except Exception:
        return None

def create_cache_hit_pie_chart(hits, misses):
    """åˆ›å»ºç¼“å­˜å‘½ä¸­ç‡é¥¼å›¾"""
    if not ADVANCED_FEATURES:
        return None

    try:
        import plotly.graph_objects as go

        fig = go.Figure(data=[go.Pie(
            labels=['æ•°æ®è¦†ç›–', 'å¾…è¡¥å……'],
            values=[hits, misses],
            hole=.3,
            marker_colors=['lightgreen', 'lightgray']
        )])

        fig.update_layout(
            title='æ•°æ®è¦†ç›–åˆ†å¸ƒ',
            height=400
        )

        return fig
    except Exception:
        return None

if __name__ == "__main__":
    main()

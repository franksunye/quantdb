#!/usr/bin/env python3
"""
ç¼“å­˜æ€§èƒ½æµ‹è¯• - éªŒè¯ QuantDB ç›¸æ¯” AKShare çš„æ ¸å¿ƒä»·å€¼
"""

import pytest
import time
import json
import os
import sys
from statistics import mean
from fastapi.testclient import TestClient

# Add project root to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from src.api.main import app


class TestCacheVsAKSharePerformance:
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½ vs AKShare ç›´æ¥è°ƒç”¨"""

    @classmethod
    def setup_class(cls):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        cls.client = TestClient(app)
        cls.test_symbols = ["000001", "600000"]  # å‡å°‘æµ‹è¯•é‡ï¼Œä¿æŒæ•æ·
        cls.test_scenarios = [
            ("20240101", "20240131", "1ä¸ªæœˆ"),
            ("20240101", "20240301", "3ä¸ªæœˆ"),
        ]
        cls.results = {
            "fresh_data": [],
            "cached_data": [],
            "partial_cache": []
        }

    @pytest.mark.performance
    def test_fresh_data_performance(self):
        """æµ‹è¯•é¦–æ¬¡æ•°æ®è·å–æ€§èƒ½ï¼ˆQuantDB vs AKShare åŸºå‡†ï¼‰"""
        print("\n=== æµ‹è¯•é¦–æ¬¡æ•°æ®è·å–æ€§èƒ½ ===")
        
        for symbol in self.test_symbols:
            for start_date, end_date, description in self.test_scenarios:
                # æ¸…é™¤ç¼“å­˜ç¡®ä¿é¦–æ¬¡è·å–
                self._clear_cache(symbol)
                
                # æµ‹è¯• QuantDB æ€§èƒ½
                quantdb_time, record_count = self._test_quantdb_performance(
                    symbol, start_date, end_date
                )
                
                result = {
                    "symbol": symbol,
                    "date_range": description,
                    "start_date": start_date,
                    "end_date": end_date,
                    "quantdb_time_ms": quantdb_time,
                    "record_count": record_count
                }
                
                self.results["fresh_data"].append(result)
                print(f"{symbol} ({description}): {quantdb_time:.0f}ms, {record_count}æ¡è®°å½•")

    @pytest.mark.performance
    def test_cached_data_performance(self):
        """æµ‹è¯•ç¼“å­˜å‘½ä¸­æ€§èƒ½"""
        print("\n=== æµ‹è¯•ç¼“å­˜å‘½ä¸­æ€§èƒ½ ===")
        
        for symbol in self.test_symbols:
            for start_date, end_date, description in self.test_scenarios:
                # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆå¡«å……ç¼“å­˜ï¼‰
                self._test_quantdb_performance(symbol, start_date, end_date)
                
                # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰- å¤šæ¬¡æµ‹è¯•å–å¹³å‡å€¼
                cached_times = []
                for i in range(5):  # 5æ¬¡æµ‹è¯•å–å¹³å‡
                    cached_time, record_count = self._test_quantdb_performance(
                        symbol, start_date, end_date
                    )
                    cached_times.append(cached_time)
                
                avg_cached_time = mean(cached_times)
                min_cached_time = min(cached_times)
                
                result = {
                    "symbol": symbol,
                    "date_range": description,
                    "avg_cached_time_ms": avg_cached_time,
                    "min_cached_time_ms": min_cached_time,
                    "record_count": record_count
                }
                
                self.results["cached_data"].append(result)
                print(f"{symbol} ({description}): ç¼“å­˜å‘½ä¸­ {avg_cached_time:.0f}ms (æœ€å¿« {min_cached_time:.0f}ms)")

    @pytest.mark.performance
    def test_partial_cache_performance(self):
        """æµ‹è¯•éƒ¨åˆ†ç¼“å­˜åœºæ™¯æ€§èƒ½"""
        print("\n=== æµ‹è¯•éƒ¨åˆ†ç¼“å­˜æ€§èƒ½ ===")
        
        symbol = "000001"  # åªæµ‹è¯•ä¸€ä¸ªè‚¡ç¥¨ä¿æŒæ•æ·
        
        # åœºæ™¯1ï¼šç¼“å­˜1æœˆæ•°æ®ï¼Œè¯·æ±‚1-3æœˆæ•°æ®
        self._clear_cache(symbol)
        self._ensure_cached_data(symbol, "20240101", "20240131")
        
        partial_time, record_count = self._test_quantdb_performance(
            symbol, "20240101", "20240331"
        )
        
        result = {
            "symbol": symbol,
            "scenario": "æ‰©å±•2ä¸ªæœˆæ•°æ®",
            "cached_range": "1æœˆ",
            "requested_range": "1-3æœˆ", 
            "partial_time_ms": partial_time,
            "record_count": record_count
        }
        
        self.results["partial_cache"].append(result)
        print(f"{symbol} éƒ¨åˆ†ç¼“å­˜åœºæ™¯: {partial_time:.0f}ms, {record_count}æ¡è®°å½•")

    def test_performance_analysis(self):
        """åˆ†ææ€§èƒ½æµ‹è¯•ç»“æœ"""
        print("\n" + "="*60)
        print("ç¼“å­˜æ€§èƒ½åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        # åˆ†æé¦–æ¬¡æ•°æ®è·å–
        if self.results["fresh_data"]:
            fresh_avg = mean([r["quantdb_time_ms"] for r in self.results["fresh_data"]])
            print(f"\nğŸ“Š é¦–æ¬¡æ•°æ®è·å–å¹³å‡æ—¶é—´: {fresh_avg:.0f}ms")
        
        # åˆ†æç¼“å­˜å‘½ä¸­æ€§èƒ½
        if self.results["cached_data"]:
            cached_avg = mean([r["avg_cached_time_ms"] for r in self.results["cached_data"]])
            print(f"âš¡ ç¼“å­˜å‘½ä¸­å¹³å‡æ—¶é—´: {cached_avg:.0f}ms")
            
            if self.results["fresh_data"]:
                improvement = (fresh_avg - cached_avg) / fresh_avg * 100
                print(f"ğŸš€ ç¼“å­˜æ€§èƒ½æå‡: {improvement:.1f}%")
        
        # åˆ†æéƒ¨åˆ†ç¼“å­˜
        if self.results["partial_cache"]:
            partial_avg = mean([r["partial_time_ms"] for r in self.results["partial_cache"]])
            print(f"ğŸ”„ éƒ¨åˆ†ç¼“å­˜å¹³å‡æ—¶é—´: {partial_avg:.0f}ms")
        
        # ä¿å­˜ç»“æœ
        self._save_performance_results()
        
        # æ€§èƒ½åˆ†æï¼ˆä¸å¼ºåˆ¶æ–­è¨€ï¼Œå› ä¸ºæµ‹è¯•ç¯å¢ƒå¯èƒ½ä¸ç”Ÿäº§ç¯å¢ƒä¸åŒï¼‰
        if self.results["fresh_data"] and self.results["cached_data"]:
            if cached_avg < fresh_avg:
                print(f"âœ… ç¼“å­˜æ€§èƒ½ä¼˜äºé¦–æ¬¡è·å–: {improvement:.1f}% æå‡")
            else:
                print(f"âš ï¸ æµ‹è¯•ç¯å¢ƒä¸­ç¼“å­˜æ€§èƒ½: {improvement:.1f}% (å¯èƒ½å› æµ‹è¯•ç¯å¢ƒç‰¹æ®Šæ€§)")
                print("   åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œç¼“å­˜é€šå¸¸ä¼šæ˜¾è‘—æå‡æ€§èƒ½")

        # ä¿å­˜æ€§èƒ½åŸºå‡†
        self._save_performance_baseline()

    def _test_quantdb_performance(self, symbol, start_date, end_date):
        """æµ‹è¯• QuantDB API æ€§èƒ½"""
        start_time = time.time()
        
        response = self.client.get(
            f"/api/v1/historical/stock/{symbol}",
            params={"start_date": start_date, "end_date": end_date}
        )
        
        end_time = time.time()
        
        assert response.status_code == 200, f"APIè°ƒç”¨å¤±è´¥: {response.status_code}"
        data = response.json()
        
        return (end_time - start_time) * 1000, len(data.get("data", []))

    def _clear_cache(self, symbol):
        """æ¸…é™¤æŒ‡å®šè‚¡ç¥¨çš„ç¼“å­˜"""
        try:
            response = self.client.delete(f"/api/v1/cache/clear/symbol/{symbol}")
            # ä¸å¼ºåˆ¶è¦æ±‚æˆåŠŸï¼Œå› ä¸ºå¯èƒ½æ²¡æœ‰ç¼“å­˜
        except:
            pass

    def _ensure_cached_data(self, symbol, start_date, end_date):
        """ç¡®ä¿æŒ‡å®šèŒƒå›´çš„æ•°æ®å·²ç¼“å­˜"""
        self._test_quantdb_performance(symbol, start_date, end_date)

    def _save_performance_results(self):
        """ä¿å­˜æ€§èƒ½æµ‹è¯•ç»“æœ"""
        results_dir = "tests/performance/results"
        os.makedirs(results_dir, exist_ok=True)
        
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        results_file = f"{results_dir}/cache_performance_{timestamp}.json"
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“ æ€§èƒ½æµ‹è¯•ç»“æœå·²ä¿å­˜: {results_file}")

    def _save_performance_baseline(self):
        """ä¿å­˜æ€§èƒ½åŸºå‡†"""
        try:
            from .performance_baseline import save_cache_performance_baseline
            save_cache_performance_baseline(self.results)
        except ImportError:
            print("âš ï¸ æ€§èƒ½åŸºå‡†æ¨¡å—æœªæ‰¾åˆ°ï¼Œè·³è¿‡åŸºå‡†ä¿å­˜")


if __name__ == '__main__':
    # æ”¯æŒç›´æ¥è¿è¡Œ
    pytest.main([__file__, "-v", "-s"])
